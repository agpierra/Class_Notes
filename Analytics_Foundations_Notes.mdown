# Day 1-3

![alt text](Pictures/overview_stats_models.png)

## Proc MEANS

```
proc means data = *SAS-data-set* options;
	class *variables*;
	var *variables*;
run;
```

`class` specifies variables whose values define the subgroup gombinations for the anlysis.

`var` specifies numeric variables for which you want to calculate descriptive statistics.

In `proc means` statement options:
- `clm` requests confidence limits for the mean
- `stderr` requests the standard error of the mean
- `alpha=` constructs confidence intervals with a different confidence level

### Example

```
proc means data=sasuser.testscores;
    var SATScore;
    title 'Descriptive Statistics Using PROC MEANS';
run;
```

Produces:

```
                                      The MEANS Procedure

                                 Analysis Variable : SATScore

               N            Mean         Std Dev         Minimum         Maximum
              ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
              80         1190.63     147.0584466     890.0000000         1600.00
              ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
```

By default, SAS prints the lines above. You can add options to means statement to request additional or alternate statistics.


```
/*st101d01.sas*/  /*Part C*/
proc means data=sasuser.testscores 
           maxdec=2 
           n mean median std q1 q3 qrange;
    var SATScore;
    title 'Selected Descriptive Statistics for SAT Scores';
run;
```

Produces:

```
                                      The MEANS Procedure

                                 Analysis Variable : SATScore

                                                          Lower          Upper       Quartile
  N           Mean         Median        Std Dev       Quartile       Quartile          Range
 ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
 80        1190.63        1170.00         147.06        1085.00        1280.00         195.00
 ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ

```

### Exercise

Data in sasuser.NormTemp is from an article which questions the notion that the true mean body temperature is 98.6. There are 65 males and 65 females. There is also some question about whether mean body temperatures for women are the same as for men. The variables in data are:

`ID` Identification number

`BodyTemp` Body temperature

`Gender` Coded(M,F)

`HeartRate` Heart rate in bpm

Use `proc means` to answer:
- What is the overall mean and std of body temp in sample?
- what is the interquartile range of body temperature?
- Do the mean values seem to differ between men and women?
	- Hint: Use the `Class` statement in `proc means` with `gender` as the class variable

```	
proc means data=sasuser.NormTemp maxdec=2 mean std q1 q3 qrange;
	var BodyTemp;
	class gender;
run;
```

a) Overall mean is 98.25

b) Interquartile range is 0.90

c) Values somewhat differ


## Statistical Graphics Procedures in SAS

`proc sgscatter` creates single-cell and multi-cell scatter plots and scatter plot matrics with optional fits and ellipses.

`proc sgplot` creates single-cell plots with a variety of plot and chart types.

`proc sgpanel` creates single-page or multi-page panels of plots and charts conditional on classification variables.

`proc sgrender` provides a way to create plots from graph templates that you modified or wrote yourself.

## Proc UNIVARIATE

```
proc univariate data=*SAS-data-set* options;
	var *variables*;
	id *variable*;
	histogram *variables* / options;
	probplot *variables* / options;
	inset *keywords* / options;
run;
```

`var` specifies numeric variables to analyze

`id` specifies a variable used to label the five lowest and five highest values in the output

`histogram` creates high-resolution histograms

`probplot` creates a high-resolution Q-Q plot

`inset` places a box or table of summary statistics (called an inset) directly in a graph created with a `cdfplot`, `histogram`, `ppplot`, `probplot`, or `qqplot` statement. The `inset` statement **must** follow the `plot` statement that creates the plot that you want to augment.

`gpath= *file-specification* <(url=)>` specifies location for all graphics output generated while destination is open

**Selected option for** `HISTOGRAM` and `PROBPLOT` **statements:**

`normal<(options)>` creates a normal probability plot.
- options `(mu= sigma=)` determine the mean and std of the normal distribution used to create reference lines.
- curve overlays in `histogram` and diagonal reference line in `probplot`
- The est option requests that the value be estimated from the data `(mu=est sigma=est)`

**Selected option for** `HISTOGRAM` **statement:**

`kernel` superimposes kernel density estimates on the histogram

### Example

```
/*st101d02.sas*/  /*Part A*/
proc univariate data=sasuser.testscores;
    var SATScore;
    histogram SATScore / normal(mu=est sigma=est) kernel;
    inset skewness kurtosis / position=ne;
    probplot SATScore / normal(mu=est sigma=est);
    inset skewness kurtosis;
    title 'Descriptive Statistics Using PROC UNIVARIATE';
run;
```

Produces:

```
                                   The UNIVARIATE Procedure
                                      Variable:  SATScore

                                            Moments

                N                          80    Sum Weights                 80
                Mean                 1190.625    Sum Observations         95250
                Std Deviation      147.058447    Variance            21626.1867
                Skewness           0.64202018    Kurtosis            0.42409987
                Uncorrected SS      115115500    Corrected SS        1708468.75
                Coeff Variation    12.3513656    Std Error Mean      16.4416342


                                  Basic Statistical Measures

                        Location                    Variability

                    Mean     1190.625     Std Deviation          147.05845
                    Median   1170.000     Variance                   21626
                    Mode     1050.000     Range                  710.00000
                                          Interquartile Range    195.00000


                                  Tests for Location: Mu0=0

                       Test           -Statistic-    -----p Value------

                       Student's t    t  72.41525    Pr > |t|    <.0001
                       Sign           M        40    Pr >= |M|   <.0001
                       Signed Rank    S      1620    Pr >= |S|   <.0001


                                   Quantiles (Definition 5)

                                    Quantile      Estimate

                                    100% Max          1600
                                    99%               1600
                                    95%               1505
                                    90%               1375
                                    75% Q3            1280
                                    50% Median        1170
                                    25% Q1            1085
                                    10%               1020
                                    5%                 995
                                    1%                 890
                                    0% Min             890


                                     Extreme Observations

                             ----Lowest----        ----Highest---

                             Value      Obs        Value      Obs

                               890       69         1490        8
                               910       74         1520       42
                               970        6         1520       54
                               990       51         1590       70
                              1000        4         1600       25

```

- Mean of data is 1190.625. Approximately equal to median = 1170.
	- Distribution is fairly symmetric
- Standard deviation is 147.058.
	- Average variability around mean is appx. 147 points
- Distribution is slightly skewed to the right
- Distribution ahs slightly heavier tales than normal distribution

![alt text](Pictures/proc_uni_dist.png)

Bin identified with midpoint of 1100 has approximately 33% of the values.


```

                               Parameters for Normal Distribution

                                 Parameter   Symbol   Estimate

                                 Mean        Mu       1190.625
                                 Std Dev     Sigma    147.0584


                        Goodness-of-Fit Tests for Normal Distribution

                Test                  ----Statistic-----   ------p Value------

                Kolmogorov-Smirnov    D       0.08382224   Pr > D       >0.150
                Cramer-von Mises      W-Sq    0.09964577   Pr > W-Sq     0.114
                Anderson-Darling      A-Sq    0.70124822   Pr > A-Sq     0.068


                               Quantiles for Normal Distribution

                                          -------Quantile------
                                Percent    Observed   Estimated

                                    1.0     890.000     848.516
                                    5.0     995.000     948.735
                                   10.0    1020.000    1002.162
                                   25.0    1085.000    1091.436
                                   50.0    1170.000    1190.625
                                   75.0    1280.000    1289.814
                                   90.0    1375.000    1379.088
                                   95.0    1505.000    1432.515
                                   99.0    1600.000    1532.734
```

![alt text](Pictures/proc_uni_qq.png)

45-degree line represents where the data values would fall if they came from normal distribution. There does not appear to be any severe departure from normality.

We use **Kolmogorov-Smirnov** and **Anderson-Darling** to determine if the distribution is normal. Null hypothesis is that distribution is normal. **High p-values are desirable** for normality.

### Exercises

Use sasuser.NormTemp data to answer:

- What are the minimum, maximum, mean and the std for BodyTemp? Does the variable appear to be normally distributed?

```
proc univariate data=sasuser.NormTemp noprint;
	var BodyTemp;
	histogram BodyTemp / normal(mu=est sigma=est noprint) kernel;
	inset min max skewness kurtosis / position=ne;
	probplot BodyTemp / normal(mu=est sigma=est);
	inset min max skewness kurtosis;
run;
```

The distribution appears approximately normal.



## Proc SGPLOT

Procedure creates one or more plots and overlays them on a single set of axes. You can use `SGPLOT` to create statistical graphics such as histograms and regression plots, in addition to simple graphics such as box plots, scatter plots and line plots.

```
proc sgplot <*options*>;
	dot *category-variable* / options;
	hbar *category-variable* / options
	hbox *response-variable* / options
	histogram *response-variable* / options
	needle x = *variable* y = *numeric-variable* / options
	reg x = *numeric-variable* y = *numeric-variable* / options
	scatter x = *variable* y = *variable* / options
	vbar *category-variable* / options
	vbox *response-variable* / options
run;
```

`Vbox` creates a vertical box plot showing the distribution of data
	- `datalabel = option` adds data labels for **outlier markers**

`Hbox` creates a horizontal box plot showing the distribution of data

### Examples

```
/*st101d02.sas*/  /*Part B*/
proc sgplot data=sasuser.testscores;
    vbox SATScore / datalabel=IDNumber;
    format IDNumber 8.;
    refline 1200 / axis=y label;
    title "Box-and-Whisker Plots of SAT Scores";
run;
```

`refline *variable|value-1 ... value-n*` creates a horizontal or vertical reference line
	- `/ axis=` places axis on x or y

`noprint` in `proc univariate` and `histogram` statements suppresses the printing of the tabular output (often used when stats are being reported in insets of plot)


We can also use proc univariate to conduct t-tests:

```
ods graphics off;
proc univariate data=sasuser.testscores mu0=1200;
    var SATScore;
    title 'Testing Whether the Mean of SAT Scores = 1200';
run;
ods graphics on;
```

`mu0=` specifies the value of the mean or location parameter in the null hypothesis for tests of location

Outputs

```
                                 Tests for Location: Mu0=1200

                       Test           -Statistic-    -----p Value------

                       Student's t    t   -0.5702    Pr > |t|    0.5702
                       Sign           M        -5    Pr >= |M|   0.3019
                       Signed Rank    S      -207    Pr >= |S|   0.2866
```

The t-statistic and p-value are labeled Student's t and Pr > |t| respectively

We cannot reject null hypothesis at the 0.05 level in this case


### Exercises

Use sasuser.NormTemp data to answer:

b) Create box plots for BodyTemp. Use ID to identify outliers. Display a reference line at 98.6 degrees. Does the average body temperature seem to be 98.6 degrees?

```
proc sgplot data=sasuser.NormTemp;
	vbox BodyTemp / datalabel=ID;
	format ID 3.;
	refline 98.6 / axis = y label;
run;
```

The average body temperature seems to be somewhat less than 98.6 degrees as was seen in the tabular output

### Plotting scatter plots

```
/* st201d02.sas */

options formdlim="_";
title1 "Sasuser.Paper Data Set";
ods html close;
ods listing;
proc sgplot data=sasuser.paper;
 scatter x=amount y=strength;
 title2 "Scatter Plot";
run;
```



## Proc TTEST

The TTest procedure performs t-tests and computes confidence limits for one sample, paired observations, two independent sample, and the AB/BA crossover design. Can also be used to produce histograms, QQ plots, box plots, and confidence limit plots.

```
proc ttest data=*SAS-data-set*;
	class *variable*;
	paired *variables*;
	var *variables*;
run;
```

`class` specifies the two-level variable for the analysis. **Only one variable** is allowed in the `class` statement.

`paired *pairlists*` specifies the `pairlists` to identify the variables to be compaired in paired comparisons

`var` specifies *numeric* response variables for the analysis



### Example

```
proc ttest data=sasuser.testscores h0=1200
           plots(shownull)=interval;
    var SATScore;
    title 'Testing Whether the Mean of SAT Scores = 1200 '
          'Using PROC TTEST';
run;
```

`H0=` specifies the value of the mean or location parameter in the null hypothesis for tests of location (=0 by default)

`plots(shownull) = interval` includes a plot of *confidence intervals* of the mean. `shownull` places a vertical reference line at the mean value of the null hypothesis

Output:

```
                                     The TTEST Procedure

                                      Variable:  SATScore

                  N        Mean     Std Dev     Std Err     Minimum     Maximum

                 80      1190.6       147.1     16.4416       890.0      1600.0

                    Mean       95% CL Mean        Std Dev      95% CL Std Dev

                  1190.6      1157.9   1223.4       147.1       127.3    174.2

                                     DF    t Value    Pr > |t|

                                     79      -0.57      0.5702
```

Notice the 95% confidence interval around the mean includes null hypothesis value of 1200, implying a lack of statistical significance at the alpha=0.05 level.

Along with this table, we get a QQ plot and the following:

![alt text](Pictures/ttest_plots.png)

## Proc Corr

You can use corr procedure to produce correlation statistics and scatter plots for your data. By default, it produces pearson correlation statistics and corresponding p-values

```
proc corr data=*saas-data-set* options;
	var *variables*;
	with *variables*;
	id *variables*;
run;
```

In the `proc corr` line, you can use:

`plots <(only)> = ( xxxxxx )`

where xxxxx =
- ALL
- Matrix
- Scatter
- Histogram
- Nvar=all|n
- Ellipse=prediction|confidence|none

### Example

```
ods graphics / reset=all imagemap;
proc corr data=sasuser.fitness rank
          plots(only)=scatter(nvar=all ellipse=none);
    var RunTime Age Weight Run_Pulse
        Rest_Pulse Maximum_Pulse Performance;
    with Oxygen_Consumption;
    id name;
    title "Correlations and Scatter Plots with Oxygen_Consumption";
run;
```

Measures oxygen consumption vs all the `var` variables.

```
/*st103d01.sas*/  /*Part B*/
ods graphics / reset=all;
proc corr data=sasuser.fitness nosimple 
          plots=matrix(nvar=all histogram);
    var RunTime Age Weight Run_Pulse
         Rest_Pulse Maximum_Pulse Performance;
    title "Correlations and Scatter Plot Matrix of Fitness Predictors";
run;
```

Creates a matrix of plots which contains regressions of each of the `var` variables against each other. On the diagonals are histograms, as specified in the `matrix(nvar=all histogram)` line. For square matrix plot, you cannot have a `with` statement.

Low p-value -> relationship is statistically relevant. High r -> strong positive correlation. 

## Proc Reg

```
proc reg data=*SAS-data-set* options;
	model *dependents=regressors* / options
	output out=*sas-data-set* keyword=*names*;
run;
quit;
```
`output` creates a new sas data set that saves diagnostic measures calculated after fitting the model. At least one keyword=names specification is required

`plots=( )` controls plots produced through ODS graphics
- diagnotstics
- residualplot
- fitplot

**Note:** `quit` statement is required since `reg` procedure supports `run`-group processing.

### Example

```
/*st103d02.sas*/
proc reg data=sasuser.fitness;
    model Oxygen_Consumption = RunTime;
    title 'Predicting Oxygen_Consumption from RunTime';
run;
quit;
```

Results:

```
                                                        Analysis of Variance
 
                                                               Sum of           Mean
                           Source                   DF        Squares         Square    F Value    Pr > F

                           Model                     1      633.01458      633.01458      84.00    <.0001
                           Error                    29      218.53997        7.53586                     
                           Corrected Total          30      851.55455                                    


                                        Root MSE              2.74515    R-Square     0.7434
                                        Dependent Mean       47.37581    Adj R-Sq     0.7345
                                        Coeff Var             5.79442                       


                                                        Parameter Estimates
 
                                                         Parameter       Standard
                           Variable              DF       Estimate          Error    t Value    Pr > |t|

                           Intercept              1       82.42494        3.85582      21.38      <.0001
                           RunTime                1       -3.31085        0.36124      -9.17      <.0001
```


`Mean Square` is the ratio of the sum of squares and the degrees of freedom. Corresponds to the amount of variability associated with each degree of freedom for each source of variation.

`Model` is the variability explained by model (between group)

`error` is variability unexplained by model (within group)

`corrected total` is the total variability in data (Total)

F value tests whether the slope of the predictor variable is equal to 0. Small p-value (less than 0.05) means that you have enough evidence to reject the null hypothesis. Therefore, you can conclude that the simple linear regression model fits the data better than the baseline model.

`Root MSE` root mean square error is an estimate of the standard deviation of the response variable at each value of the predictor value. Square root of the MSE

`Dependent mean` is the overall mean of the response variable

`Coeff Var` is the size of the standard deviation relative to the mean. Calculated as (RootMSE/dependentmean)*100


For **paramater estimate** table:

`Parameter estimate` is the estimated beta value in the simple linear regression

`t value` is the t statistic which is calculated by dividing the parameter estimates by their corresponding standard error estimates



### Multiple linear regression

```
/*st103d04.sas*/
ods graphics off;
proc reg data=sasuser.fitness;
    model Oxygen_Consumption=Performance RunTime;
    title 'Multiple Linear Regression for Fitness Data';
run;
quit;

ods graphics on;
```

Results:

```
 
                                                               Sum of           Mean
                           Source                   DF        Squares         Square    F Value    Pr > F

                           Model                     2      646.33101      323.16550      44.09    <.0001
                           Error                    28      205.22355        7.32941                     
                           Corrected Total          30      851.55455                                    


                                        Root MSE              2.70729    R-Square     0.7590
                                        Dependent Mean       47.37581    Adj R-Sq     0.7418
                                        Coeff Var             5.71450                       


                                                        Parameter Estimates
 
                                                         Parameter       Standard
                           Variable              DF       Estimate          Error    t Value    Pr > |t|

                           Intercept              1       71.52626        8.93520       8.00      <.0001
                           Performance            1        0.06360        0.04718       1.35      0.1885
                           RunTime                1       -2.62163        0.62320      -4.21      0.0002
```
**Note:** Number of parameters in model includes the intercept

`model df` is the number of parameters minus 1 (3-1)

`error df` is the number of observations (31) minus the number of parameters in model (3)

`corrected total df` is number of observations minus 1

`f value` is the MeanSquareModel/MeanSquareError

small p-value -> reject the null hypothesis that B1 = B2 = 0 and conclude that at least one B_i ~= 0

For this case, the model can be written as:

**Oxygen_consumption** = 71.5626 + 0.06360x**Performance** - 2.62163x**RunTime**


### Model Selection

Can eliminate one variable at a time, but manually for large data sets can take an extreme amount of time.

Model Selection options
- Stepwise
- Forward
- Backward

All possible regressions ranked using
- RSquare
- AdjRSQ
- CP

Mallows' Cp
- Indicator of effective variable selection within model
- **Look for models** with `Cp <= p`, where p equals the number of parameters in the model, **including the intercept**
- Mallows recommends choosing the first (fewest variables) model where Cp approaches p

Hocking's criterion
- `Cp <= p` for prediction
- `Cp <= 2p - pfull + 1` for parameter estimation

```
/*st103d05.sas*/  /*Part A*/
ods graphics / imagemap=on;

proc reg data=sasuser.fitness plots(only)=(rsquare adjrsq cp);
    ALL_REG: model oxygen_consumption 
                    = Performance RunTime Age Weight
                      Run_Pulse Rest_Pulse Maximum_Pulse
            / selection=rsquare adjrsq cp;
    title 'Best Models Using All-Regression Option';
run;
quit;
```

`selection=` enables you to choose the different selection models. First listed is the one that determines the sorting order in output
	- RSQUARE
	- ADJRSQ
	- CP

```
/*st103d05.sas*/  /*Part B*/
ods graphics / imagemap=on;

proc reg data=sasuser.fitness plots(only)=(cp);
    ALL_REG: model oxygen_consumption 
                    = Performance RunTime Age Weight
                      Run_Pulse Rest_Pulse Maximum_Pulse
            / selection=cp rsquare adjrsq best=20;
    title 'Best Models Using All-Regression Option';
run;
quit;
```

`best= n` selects the best n models

```
/*st103d06.sas*/
ods graphics off;
proc reg data=sasuser.fitness;
   PREDICT: model Oxygen_Consumption 
                  = RunTime Age Run_Pulse Maximum_Pulse;
   EXPLAIN: model Oxygen_Consumption 
                  = RunTime Age Weight Run_Pulse Maximum_Pulse;
   title 'Check "Best" Two Candidate Models';
run;
quit;

ods graphics on;
```

Can have multiple regressions in same proc reg. Above we are testing the best 'predict' and best 'explain' (see hookings criterion)

### Stepwise selection

`Forward` selects the best one-variable model. Then it selects the best two variables among those that contain the first variable. Stops when it reaches the point where no additional variables have p-value levels less than some stopping criterion (0.50, by default)

`Backward` starts with full model. Next, the variable that is least significant, give the other variables is removed from the model. Continues this process until all of the remaining variables have p-values less than a stopping criterion value (0.10 by default)

`Stepwise` works like a combination of forward and backward. Default entry p-value is 0.15 and the default stay p-value is also 0.15.

**Caution**: Automated model selection results in:
- Biases in parameter estimates, predictions and standard errors
- Incorrect calculation of degrees of freedom
- p-values that tend to err on the side of overestimating significance (increasing type 1 error probability)

```
/*st103d07.sas*/

proc reg data=sasuser.fitness plots(only)=adjrsq;
   FORWARD:  model oxygen_consumption 
                    = Performance RunTime Age Weight
                      Run_Pulse Rest_Pulse Maximum_Pulse
            / selection=forward Slentry=0.10;
   BACKWARD: model oxygen_consumption 
                    = Performance RunTime Age Weight
                      Run_Pulse Rest_Pulse Maximum_Pulse
            / selection=backward Slstay=0.10;
   STEPWISE: model oxygen_consumption 
                    = Performance RunTime Age Weight
                      Run_Pulse Rest_Pulse Maximum_Pulse
            / selection=stepwise;
   title 'Best Models Using Stepwise Selection';
run;
quit;
```

### Regression of higher degrees

```
proc sgplot data=sasuser.paper;
    reg  x=amount y=strength / lineattrs =(color=brown       
         pattern=solid) legendlabel="Linear";
title2 "Linear Model";
run; 

proc sgplot data=sasuser.paper;
    reg  x=amount y=strength / degree=2 lineattrs =(color=green       
         pattern=mediumdash) legendlabel="2nd Degree";
title2 "Second Degree Polynomial";
run;

proc sgplot data=sasuser.paper;
   reg  x=amount y=strength / degree=3 lineattrs =(color=red   
        pattern=shortdash) legendlabel="3rd Degree";
title2 "Third Degree Polynomial";
run;

proc sgplot data=sasuser.paper;
    reg  x=amount y=strength / degree=4 lineattrs =(color=blue
      pattern=longdash) legendlabel="4th Degree";
title2 "Fourth Degree Polynomial";
run; 
```

`degree=` specifies the degree of the polynomial fit

You cannot create powers of variables within `proc reg`. We must run a data step that creates necessary items.

```
/* st201d03.sas */
title;
title2;

data paper;
   set sasuser.paper;
   amount2 = amount**2;
   amount3 = amount**3;
   amount4 = amount**4;
run;

proc reg data=paper ;
   model strength= amount amount2 amount3 amount4 / scorr1(tests);
title "Paper Data Set: 4th Degree Polynomial";
run;
quit;
```

`score1` displays the squared semi-partial correlation coefficients using type 1 sums of squares.
- `tests` requests f-tests, p-values and cumulative r-square values because variables are sequentially added to a model. Uses f-test demoninator MSE for the full model specified in model statement.
- `seqtests` uses f-test denominator MSE for  model containing all the independent variables that were added to the model up to and including variable in question 

```
                                                        Parameter Estimates
 
                                                                                   Squared
                           Parameter       Standard                           Semi-partial     Cumulative    ------Type I-----
      Variable     DF       Estimate          Error    t Value    Pr > |t|     Corr Type I       R-Square    F Value    Pr > F

      Intercept     1        3.43333        0.80170       4.28      0.0005               .              0        .       .    
      Amount        1       -1.68444        1.45927      -1.15      0.2643         0.54625        0.54625      36.11    <.0001
      amount2       1        1.02389        0.87380       1.17      0.2575         0.10748        0.65372       7.11    0.0163
      amount3       1       -0.22222        0.20982      -1.06      0.3044         0.07620        0.72992       5.04    0.0384
      amount4       1        0.01611        0.01743       0.92      0.3682         0.01293        0.74285       0.85    0.3682

```

Although it appears that none of the slopes are significantly different than 0, it is because the p values calculated are given that all the other variables are in the model.

Type I p-values are sequential. Calculate the significance of a variable given the previous variables are in the model.

Fitting a cubic model:

```
/* st201d04.sas */
proc reg data=paper plots (unpack) =(diagnostics (stats=none)); 
   Cubic_Model: model strength=amount amount2 amount3 / lackfit 
   scorr1(tests);
title "Paper Data Set: 3rd Degree Polynomial";   
run;
quit;
```

`lackfit` performs a lack of fit test. Compares the variation around the model with 'pure' variation within replicated observations. This test measures the adequacy of the specified model and can be specified only if some observations in your design are replicated

```
                                                        Parameter Estimates
 
                                                                                   Squared
                           Parameter       Standard                           Semi-partial     Cumulative    ------Type I-----
      Variable     DF       Estimate          Error    t Value    Pr > |t|     Corr Type I       R-Square    F Value    Pr > F

      Intercept     1        2.73280        0.26060      10.49      <.0001               .              0        .       .    
      Amount        1       -0.36900        0.32208      -1.15      0.2669         0.54625        0.54625      36.41    <.0001
      amount2       1        0.22339        0.11651       1.92      0.0712         0.10748        0.65372       7.16    0.0154
      amount3       1       -0.02862        0.01270      -2.25      0.0369         0.07620        0.72992       5.08    0.0369
```

Overall F-test is significant.

Lack of fit test is not significant (pvalue 0.36820), therefore there is no inadequacy of the specefied model. Type I test shows that all three slopes are significant in model.

### Multicollinearity

VIF > 10 -> presence of strong collinearity

Condition index
- Between 10 and 30 suggest weak dependencies
- Between 30 and 100 indicate moderate dependencies
- Greater than 100 indicate strong collinearity
- For large condition index, proportion of variation explained by principal components > 0.5

Using `Collin` and `collinnoint`

![alt text](Pictures/collin_stat.png)

```
/* st201d05.sas */
title 'Collinearity Diagnosis for the Cubic Model';

proc corr data=paper nosimple plots=matrix;
   var amount amount2 amount3;
run;

proc reg data=paper;
   model strength=amount amount2 amount3 / vif collin collinoint;
run;
quit;
title; 
```

`nosimple` suppresses printing simple descriptive stats for each variable

`vif` produces variance inflation factors with parameter estimates

`collin` requests a detailed analysis of collinearity among the regressors

`collinoint` requests the same analysis as `collin` with the intercept variable adjusted out rather than included in diagnostics

### Model diagnostics

```
/* st202d01.sas */
ods graphics / imagemap=on;
ods listing close;
ods html style=analysis;
proc reg data=sasuser.cars2  plots (label)=all;
   model price = hwympg hwympg2 horsepower
     / vif collin collinoint influence spec partial;
   id model;
   output out=check r=residual p=pred rstudent=rstudent h=leverage;
run;
quit;
```

`influence` requests that a detailed analysis of the influence of each observation on the estimate and the predicted values be prented

`spec` performs a test so that the first and second moments of the model are correctly specified. Null hypothesis maintains that the errors are homoscedastic, independent of the regressors, and that several technical assumptions about the model specification are valid.

`partial` requests partial regression leverage plots for each regressor

```
                                                         The REG Procedure
                                                           Model: MODEL1
                                                     Dependent Variable: Price 

                                                      Test of First and Second
                                                        Moment Specification
 
                                                     DF    Chi-Square    Pr > ChiSq

                                                      8         16.49        0.0359
                                                                                                  23

                                                         The REG Procedure
                                                           Model: MODEL1
                                                     Dependent Variable: Price 

                                                         Output Statistics
 
                                                     Hat Diag        Cov              -------------------DFBETAS------------------
      Obs            Model    Residual    RStudent          H      Ratio     DFFITS   Intercept     Hwympg    hwympg2   Horsepower

        1   Integra            -1.0276     -0.2177     0.0244     1.0774    -0.0344      0.0059    -0.0218     0.0232      -0.0151
        2   Legend              5.2465      1.1274     0.0367     1.0236     0.2199     -0.0266    -0.0837     0.0843       0.0424
        3   100                12.9697      2.8930     0.0239     0.7108     0.4527      0.0885    -0.2313     0.1656      -0.0353
        4   90                  4.3697      0.9304     0.0239     1.0317     0.1456      0.0285    -0.0744     0.0533      -0.0113
        5   535i                5.6921      1.2598     0.0882     1.0639     0.3917     -0.2901     0.3016    -0.2385       0.3528
```

In log window, there is warning due to higher ordered terms. May want to consider alternative to evaluate constant variance assumption instead of moment specification.

**Note:** null hpyothesis for chi-square test in the first and second moment specification is:
- Errors are homoscedastic
- Errors are independent of the regressors
- Several technical assumptions about the model specification are valid. For example, correct model is specified

Included in output is partial influence option output

By evaluating histogram distribution of residuals for price and Q-Q plot of residuals for price, we do not see any major problems with normality assummption

Plot of residuals versus predicted values may cause concern for the assumption of equal variances. This can be evaluated with spearman rank correlation coefficient between the absolute values of the residuals and the predicted values.

```
data check;
   set check;
   abserror=abs(residual);
run;

proc corr data=check spearman nosimple;
   var abserror pred;
run;
```

Output:

```
                                                 2  Variables:    abserror pred     


                                             Spearman Correlation Coefficients, N = 81 
                                                     Prob > |r| under H0: Rho=0
 
                                                                      abserror          pred

                                        abserror                       1.00000       0.60274
                                                                                      <.0001

                                        pred                           0.60274       1.00000
                                        Predicted Value of Price        <.0001              
```

Spearman rank correlation coefficient between the absolute values of residuals and predicted values is 0.603. High p-value (<0.0001) indicates a strong correlation between absolute values of residuals and predicted values. Residuals increase as predicted values increase.


To assess model fit, examine plots of residuals versus independent variables, rf plot, and the plot of observed values vs predicted.

Residual-Fit spread plot shows that model is a good fit and explains most of the variation in the data

## Proc stdize

```
proc stdize options;
	var *variables*;
run;
```

```
/* st201d06.sas */
options formdlim="_";
proc stdize data=sasuser.paper method=mean out=paper1(rename=(amount=mcamount));
   var amount;
run;

data paper1;
   set paper1;
   mcamount2 = mcamount**2;
   mcamount3 = mcamount**3;
run;                               *ST201d06.sas;      
```

`method=` specifies the name of the method for computing location and scale measures.
- `mean` `median` `std` `range`
- `method=mean` subtracts the mean of the variable for every observation.

We can also do this in SQL:

```
/***altertanively, use a SQL and a DATA step to center the variable*/
proc sql;
   select mean(amount) into: mamount
   from sasuser.paper;
run;

data paper2;
   set sasuser.paper;
   mcamount=amount-&mamount;
   mcamount2 = mcamount**2;
   mcamount3 = mcamount**3;
run;
```

When variables have a polynomial relationship with price, it might be wise to center these variables to rediuce collinearity problems with the models. You must create higher-order terms for the variables before using them in model statement of `proc reg`

```
/* st201d10.sas */
proc stdize data=sasuser.cars method=mean out=sasuser.cars2;
   var citympg hwympg fueltank weight;
run;

data sasuser.cars2;
   set sasuser.cars2;
   citympg2 = citympg*citympg;
   hwympg2 = hwympg*hwympg;
   fueltank2=fueltank*fueltank;
   fueltank3=fueltank2*fueltank;
run; 	

/* st201d11.sas */
ods graphics / reset=all;

title 'Model Selection Cars2 Data Set';
proc reg data=sasuser.cars2 plots(only) = criteria ;
   backward: 
   model price = citympg citympg2 hwympg hwympg2 cylinders
                 enginesize horsepower fueltank fueltank2 fueltank3
                 luggage weight
                 / selection=backward slstay=0.1;
   forward:
   model price = citympg citympg2 hwympg hwympg2 cylinders
                 enginesize horsepower fueltank fueltank2 fueltank3
                 luggage weight
                 / selection=forward slentry=0.1;
   Rsquared:
   model price = citympg citympg2 hwympg hwympg2 cylinders
                 enginesize horsepower fueltank fueltank2 fueltank3
                 luggage weight
                 / selection=rsquare adjrsq cp sbc aic best=3;
   plot cp.*np. / vaxis=0 to 30 by 5 haxis=0 to 12 by 1 
                  cmallows=red nostat nomodel;
   symbol v=circle w=4 h=1;
   Adjusted_R2:
   model price = citympg citympg2 hwympg hwympg2 cylinders
                 enginesize horsepower fueltank fueltank2 fueltank3
                 luggage weight 
                 / selection=adjrsq rsquare cp sbc aic best=10;
run;
quit;  
title;
```

`labelvars` requests list of regressors in the relevant model be used to label the best model at each value of the number of parameters. supported only when panel is unpacked.

`sbc` `aic` computes SBC and AIC stat for each model

`cmallows=` requests a Cp=p reference line and specifies color

`haxis=` `vaxis=` specifies tick mark values for horizontal axis / specifies range for vert axis



## Proc score

```
proc score data=*sas-data-set* score=*sas-data-set* out=*sas-data-set* other_options;
	var *variables*;
run;
```

Produces predicted values by outputting the parameter estimates from `proc reg` into a data set, and then scoring the new observations in `proc score`

### Example

```
/*st103d03.sas*/
data Need_Predictions;
    input RunTime @@;
    datalines;
9 10 11 12 13
;
run;
```
datalines above represent x values for which a prediction is wanted.

```
proc reg data=sasuser.fitness noprint outest=Betas;
    PredOxy: model Oxygen_Consumption=RunTime;
run;
quit;

proc print data=Betas;
    title "OUTEST= Data Set from PROC REG";
run;

proc score data=Need_Predictions score=Betas
           out=Scored type=parms;
    var RunTime;
run;
```

**Note:** `type=parms` is important when you run `proc score`

```
proc print data=Scored;
    title "Scored New Observations";
run;
```

proc reg p-option is another way to do this:

```
/*st103d03.sas*/  /*Self Study*/ 
data Need_Predictions;
    input RunTime @@;
    datalines;
9 10 11 12 13
;
run;

data Predict;
    set Need_Predictions 
        sasuser.fitness;
run;

ods graphics off;

proc reg data=Predict;
    model Oxygen_Consumption=RunTime / p;
    id RunTime;
    title 'Oxygen_Consumption=RunTime with Predicted Values';   
run;
quit;

ods graphics on;

```

## Proc SGScatter

Creates a paneled graph of scatter plots for multiple combinations of variables depending on the plot statement you use. Can create:
- paneled graphs of scatter plots
- panaled graphs of scatter plots with shared axes
- scatter plot matrix with prediction ellipses
- diagonal with histograms and density plots

```
proc sgscatter options;
	compare x= *variable|variable-1...variable-n*
			y= *variable|variable-1...variable-n*
			/ options;
	matrix variable-1 ... variable-n / options;
	plot *plot-requests* / options;
run;
```

`compare` creates a comparative panel of scatter plots with shared axes

`Matrix` creates a scatter plot matrix

`plot` creates a paneled graph that contains multiple independednt scatter plots

```
/* st201d01.sas */ /* Part A */
proc sgscatter data=sasuser.school;
 compare y=reading3
 	     x=(words1 letters1 phonics1);
 title 'Scatter Plots of READING3 by WORDS1 LETTERS1 and PHONICS1';
run; 								
```

Can also use `proc reg`

```
/* st201d01.sas */ /* Part B */
options formdlim="_";
proc reg data=sasuser.school 
	plots (only)=diagnostics (unpack);
   	model reading3 = words1 letters1 phonics1;
	output out=out r=residuals;
title 'School Data: Regression and Diagnostics';
run;
quit;   
```

`formdlim` specifies a character to delimit page breaks in sas output; 

`diagnostics(unpack)` produces a summary panel of fit diagnostics.
- `stats=` determines which model fit statistics are included in the model
- `unpack` produces the eight plots in the panel as individual plots

`r=residuals` creates a variable r in dataset out of the residuals in the model. We can then look at the distribution of these residuals in `proc univariate`

From running this, because the adjusted R-square for the model is 0.6904, the results of the three tests administered in the fall of the school year account for about 69% of the variability in the scores of the reading test administered in the spring.   



```
/* st201d01.sas */ /* Part C */
proc univariate data=out normal;
  var residuals;
run;
```

`normal` requests tests for normality that include a series of goodness-of-fit tests based on empirical distribution function. 

**Use Kolmogorov-Smirnov** and **Anderson-Darline**

Can examine examine the relationship of one variable with different variables:

```
/* st201d08.sas */
proc sgscatter data=sasuser.cars;
   plot price*(citympg hwympg cylinders enginesize horsepower fueltank
	    luggage weight); 
run;


ods graphics  / imagemap=on;
ods listing close;
ods html style=statistical;
proc sgscatter data=sasuser.cars;
 plot price*(citympg hwympg fueltank weight) / pbspline;
run;
ods html close;
ods listing;

```

When curvature is seen, may be useful to add a smooth curve to the plots.

`pbspline` adds a fitten, penalized B-spline curve to the scatter plot


#Day 4

##Chapter 2: Analysis of Variance(ANOVA)


###2.1 Regression Model Diagnostics

Objectives:
* Use the TTest procedure to analyze the differences between two population means
* Verify the assumptions of a two-sample test

**Assumptions**
- Independednt observations
- Normally distributed data for each group
- Equal variances for each group
- (Can use large smaples instead of normally distributed observations due to central limit theorem)



#### Folded F Test for Equality of Variances

```
H_o : sigma1^2 = sigma2^2
H_a : sigma1^2 ~= sigma2^2

F = max(s1^2, s2^2) / min(s1^2, s2^2)
```
The F value is calculated as a ratio of the greater of the two variances divided by the lesser of the two. F tends to be closer to 1.0 if the null hypothesis is true.
Test is valid **only** for independent samples from normal distributions. **Normality is even required for large samples!**

Note: If data is not normally distributed, you can look at plots to determine if equal variance.

![alt text](Pictures/Folded_F_Test.png "Folded F Test for Equality of Variances")

####TTEST Procedure

```
proc ttest data=_SAS-data-set_
	class _variable_;
	var _variables_;
	Paired _variable1*variable2_;
run;
```

Paired - specifies pairs of numeric response variables from which difference scores are calculated (variable1-variable2). A one-sample t test is then performed on the difference scores

####Steps for t-Test for equal/unequal means

1. Check the assumption of equal variances and then use the appropriate test for equal means
2. If calculated F > F' then use the equal variance t-test line in the output to test whether the means of the two populations are equal **(Pooled)**. Otherwise, use the unequal variance t-test **(Scatterthwaite)**.

**Before doing the appropriate test for equal means, you must do a test to see if the variances are equal.** 

####Demo: Two-sample t-test

```
/*st102d01.sas*/
proc ttest data=sasuser.TestScores plots(shownull)=interval;
    class Gender;
    var SATScore;
    title "Two-Sample t-test Comparing Girls to Boys";
run;
```

First you must verify assumptions of t-tests. Look at distribution of each gender to verify the normality of each group (looks fairly normal on page 2-9). 
Q-Q plots also approximate to a normal distritibution, with one outlier - a male scoring 1600 when no other male scored greater than 1400.


Result:
```

                                                        The TTEST Procedure
 
                                                        Variable:  SATScore

                           Gender          N        Mean     Std Dev     Std Err     Minimum     Maximum

                           Female         40      1221.0       157.4     24.8864       910.0      1590.0
                           Male           40      1160.3       130.9     20.7008       890.0      1600.0
                           Diff (1-2)            60.7500       144.8     32.3706                        

                   Gender        Method               Mean       95% CL Mean        Std Dev      95% CL Std Dev

                   Female                           1221.0      1170.7   1271.3       157.4       128.9    202.1
                   Male                             1160.3      1118.4   1202.1       130.9       107.2    168.1
                   Diff (1-2)    Pooled            60.7500     -3.6950    125.2       144.8       125.2    171.7
                   Diff (1-2)    Satterthwaite     60.7500     -3.7286    125.2                                 

                                    Method           Variances        DF    t Value    Pr > |t|

                                    Pooled           Equal            78       1.88      0.0643
                                    Satterthwaite    Unequal      75.497       1.88      0.0644

                                                       Equality of Variances
 
                                         Method      Num DF    Den DF    F Value    Pr > F

                                         Folded F        39        39       1.45    0.2545
```
1. Examine descriptive statistics for each group and their differences
2. Look at the Equality of Variances table. F test has a p-value of 0.2545 > 0.05. Therefore, do NOT reject the null hypothesis of equal variances. We continue as if the variances are equal.
3. Look at the T-Test table for the hypothesis for equal means. Use the equal variance (pooled) t-test.
	* Do not reject null hypothesis that the group means are equal P-value = 0.0643 > 0.05 . 
	* There is no significant difference in average SAT score between boys and girls
	* Note: you can also use confidence intervals. (-3.6950, 125.2) includes 0 (95% confidence interval)


### 2.2 One-Way ANOVA

![alt text](Pictures/Overview_of_statistical_models.png)

**Predictor** = Categorical 
**Response** = Continuous    ->   Use **One-Way ANOVA**

Analysis of variance is a statistical technique used to compare the means of two or more groups of observations or treatments.

*Examples of one-way anova*: 
- Do accountants, on average, earn more than teachers?
- Do people treated with one of two new drugs have higher average T-cell counts than people in the control group?
- Do people spend different amounts of depending on which type of credit card they have?


When there are three or more levels for the grouping variable, you can run a series of t tests between all the pairs of levels. However, a more powerful approach is to analyze all the data simultaneously _(one-way analysis of variance)_. In this case, **the test statistic is the F ratio** rather than the Student's t value.


####Garlic Ranch Example

-Does the type of fertilizer used affect the average weight of garlic grown at the Montana Gourmet Garlic Ranch?

Variables in the data set:
* `Fertilizer`: Type of fertilizer used (1 through 4) where 3 are organic, and one is a chemical fertilizer (as control)
* `BulbWt`: Average garlic bulb weight (in pounds) in the bed
* `Cloves`: The average number of cloves on each bulb
* `BedID`: randomly assigned bed identification number

Printing the data in the sasuse.MGGarlic dataset and create descriptive statistics:

```
/*st102d02.sas*/  /*Part A*/
proc print data=sasuser.MGGarlic (obs=10);
   title 'Partial Listing of Garlic Data';
run;
```

Data shown below:
```
                                      The MEANS Procedure

                                  Analysis Variable : BulbWt

             N
           Obs     N            Mean         Std Dev         Minimum         Maximum
           ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
            32    32           0.219           0.029           0.152           0.278
           ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ


                                  Analysis Variable : BulbWt

                     N
     Fertilizer    Obs     N            Mean         Std Dev         Minimum         Maximum
   ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
              1      9     9           0.225           0.025           0.188           0.254

              2      8     8           0.209           0.026           0.159           0.241

              3     11    11           0.230           0.026           0.189           0.278

              4      4     4           0.196           0.041           0.152           0.248
   ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
```

Look at fertilizer groups separately:
```
/*st102d02.sas*/  /*Part B*/
proc means data=sasuser.MGGarlic printalltypes maxdec=3;
    var BulbWt;
    class Fertilizer;
    title 'Descriptive Statistics of Garlic Weight';
run;

/*st102d02.sas*/  /*Part C*/
proc sgplot data=sasuser.MGGarlic;
    vbox BulbWt / category=Fertilizer datalabel=BedID;
    format BedID 5.;
    title "Box and Whisker Plots of Garlic Weight";
run;

```

`PRINTALLTYPES` displays all requested combinations of class variables (all TYPE vaalues) in the printed or displayed output.

`Class *variables*` specifies the variables whose values define the subgroup combinations for the analysis. Do not need to sort the data by class variables.

`Category =` produces separate box plots for each level of the variable listed

In this demo, the design is not balanced. The groups are not equally sized (look at N Obs in the Means procedure).

![alt text](Pictures/Anova_Null_Alternative_Hypothesis.png)


####Partitioning Variability in ANOVA

In ANOVA, Total Variation (measured by the corrected total sum of squares) is partitioned into two components:

1. The Between Group Variation (Model Sum of Squares)
	* Variability explained by the independent variable and therefore represented by the between treatment sum of squares. Calculated as the weighted (by group size) sum of the squared differences between the mean for each group and the overall mean. (SS_M) ![alt text](Pictures/Between_Group_Variation.png)
2. The Within Group variation (Error Sum of Squares)
  * Variability not explained by the model. Also referred to as _within treatement variability or residual sum of squares_. It is calculated as the sum of the squared differences between each observed value and the mean for its group. (SS_E) ![alt text](Pictures/Within_Group_Variation.png)

ANOVA breaks apart the variance of the dependent variable to determine whether the between-group variation is a significant portion of the total variation.

The test statistic (F Ratio) is only a ratio of the model variance to the error variance.

Overall variability in the response variable is calculated as the sum of the squared differences between each observed value and the overall mean. (SS_T) ![alt text](Pictures/Total_Variation.png)

**SS_T = SS_M + SS_E**

The amount of variability in the response that the model explains is given by: (SS_M / SS_T)*100%

The basic measures of variation under the two hypotheses are transformed into a ratio of the model and the error variances that has a known distribution (sample statistic, F ratio) under the null hypothesis that all group means are equal. The F ratio can be used to compute a p-value.

####F Statistic and Critical Values

F = MSM/MSE = SS_M/df_m  / SS_E/df_e

- **Model DF** = Number of treatments minus 1

- **Corrected total DF** = sample size - 1

- **Error DF** = the sample size minus the number of treatments (differenceb etween total DF and model DF)

Mean squares are calculated by taking the sums of squares and dividing by the corresponding degrees of freedom. They can be thought of as variances.
- MSE is an estimate of sigma^2, the constant variance assumed for all treatments
- If mu_i = mu_j for all i ~= j, then the mean square for the model (MSM) is also an estimate of sigma^2
- If mu_i ~= mu_j then MSM estimates sigma^2 plus a positive constant
- The p-value for the test is calculated from the F distribution with appropriate degrees of freedom 
	-(numerator = df_m, denominator = df_e)


R^2 = SS_M / SS_T

- Coefficient of determination is a measure of the proportion of variability explained


####The ANOVA Model

![alt text](Pictures/Fertilizer_Equation.png)
 
 Variables:
 - `Y_ik` = the kth value of the response variable for the ith treatment
 - `mu` = the overall population mean of the response
 - `tau_i` = the difference between the population mean of the ith treatment and the overall mean, mu. This is referred to as the *effect* of treatment i
 - `epsilon_ik` = the difference between the observed value of the kth observation in the ith group and the mean of the ith group (error term)


 #### Proc GLM

 Uses a parameterization of categorical variables in its `Class` statement that will not directly estimate the values of the parameters in the model shown. The correct parameter estimates can be obtained by adding the `solution` option in the `model` statment in `proc glm` and then using simple algebra.
 Parameter estimates and standard errors can also be obtained using the `estimate` statments.

 Fixed effect - researchers are only interested in four specific fertilizers
 Random effect - If the fertilizers used were a sample of many that can be used, the sampling variability of fertilizers would need to be taken into account in the model.

 ##### SAS code

 ```
/*st102d03.sas*/  /*Part A*/
proc glm data=sasuser.MGGarlic;
     class Fertilizer;
     model BulbWt=Fertilizer;
     title 'Testing for Equality of Means with PROC GLM';
run;
quit;


 ```

 * `Class` = specifies classification variables for analysis
 * `Model` = specifies dependent and independent variables for analysis
 * `Means` = computes unadjusted means of the dependent variable for each value of the speicified effect
 * `LSMeans` = produces adjusted means for the outcome variable, broken out by the variable specified and adjusting for any other exlanatory variables included in the `model` statment
 * `output` = specifies an output data set that contains all variables form the input data set and variables that represent statistics fromt he analysis

 ```

                                    Dependent Variable: BulbWt

                                              Sum of
      Source                      DF         Squares     Mean Square    F Value    Pr > F

      Model                        3      0.00457996      0.00152665       1.96    0.1432

      Error                       28      0.02183054      0.00077966

      Corrected Total             31      0.02641050


                      R-Square     Coeff Var      Root MSE    BulbWt Mean

                      0.173414      12.74520      0.027922       0.219082


      Source                      DF       Type I SS     Mean Square    F Value    Pr > F

      Fertilizer                   3      0.00457996      0.00152665       1.96    0.1432


      Source                      DF     Type III SS     Mean Square    F Value    Pr > F

      Fertilizer                   3      0.00457996      0.00152665       1.96    0.1432
```


Output divided into 3 parts
	- The analysis of variance table
	- Descriptive information
	- Information about the effect of the independent variable in the model


The F statistic and corresponding p-value are reported in the Analysis of Variance table. p-value (0.1432) > 0.05 and therefore, you do not reject the null hypothesis of no difference between the means.

The `BulbWt` Mean is the mean of all the data values in the variable `BulbWt` without regard to `Fertilizer`

For a one-way anova (only one classification variable) the informationa bout the independent variable in the model is an exact duplicate of the model line of the  anova table.

Default plot created is a box plot. *To check validity of Anova model, look at the diagnostic plots*. Code is below to do this:

 ```
/*st102d03.sas*/  /*Part B*/
proc glm data=sasuser.MGGarlic plots(only)=diagnostics;
     class Fertilizer;
     model BulbWt=Fertilizer;
     means Fertilizer / hovtest;
     title 'Testing for Equality of Means with PROC GLM';
run;
quit;

 ```

 Selected means statement option:

 `Hovtest` performs Levene's test for homogeneity (equality) of variances. The null hypothesis is that variances are equal (Levene's is default test)

 `Diagnostics` produces a panel display of diagnostic plots for linear models.

##### Diagnostic plots

Plot in upper left shows residuals vs fitted values from ANOVA model. Any patterns or trends in this plot indicates model misspecification

 Residual histogram and Q-Q plot at bottom left and middle left respectively test for normality assumption
 - Histogram has no unique peak and has short tales, but is approximately symmetric
 - Data values in Q-Q stay close to diagonal reference line. Strong support to assumption of normality distrbuted errors
 - You can look at the following table to check the assumptions of equal variances (output of hovtest option):

```
	             Levene's Test for Homogeneity of BulbWt Variance
                         ANOVA of Squared Deviations from Group Means

                                         Sum of        Mean
               Source            DF     Squares      Square    F Value    Pr > F

               Fertilizer         3    1.716E-6    5.719E-7       0.98    0.4173
               Error             28    0.000016    5.849E-7
```
Null hypothesis is that variances are equal over all the `fertilizer` groups. p-value 0.4173 > 0.05 and therefore you *do not* reject the jull hypothesis.

If variances were not equal, you could add the `welch` option to the `means` statement. 


####SUMMARY

Null Hypothesis: All means are equal
Alternative hypothesis: At least one mean is different

1. Produce descriptive statistics
2. Verify assumptions
	- Independence
	- Errors are normally distributed
	- Error variances are equal for all groups
3. Examine the p-value in the ANOVA table. If the p-value is less than alpha, reject the null hypothesis


### 2.3 ANOVA with Data from a Randomized Block Design

**Objectives**
- Recognize the difference between a completely randomized design aand a randomized block design
- differentiate between observed data and designed experiments
- Use the GLM procedure to analyze data from a randomized block design

**Observational or Retrospective Studies**
- Groups can be naturally occuring (gender ethnicity)
- Random assignment might be unethical or untenable (smoking or credit risk groups)
- Often you look at what already happened instead of following through to the future
- you have little control over other factors contributing to the outcome measure


Bulb weight = Fertilizer + Nuisance Factors + Random Variable

$\gamma_{ijk} = \mu + \alpha_i + \tau_j + \epsilon_{ijk}$

where Nuisance factors could be sun exposure, ph of the soil, rain

Before blocking, the variation due to the nuisance factors is contained within the sum of square errors

Because sector is included in the anova model, any effect caused by the nuisance factors that are common within a sector are accounted for in the Model Sum of Squares and not the Error Sum of Squares. Removing significant effects fromt he Error Sum of squares tends to give more power to the test of the effect of interest. This is because MSE, the denominator of the F statistic, tends to be reduced.

####Including a Blocking Variable in the Model

Additional assumptions are as follows:
- Treatments are randomly assigned within each block.
- The effects of the tratment factor are constant across the levels of the blocking variable

When the effects of the treatment factor are not constant across the levels of the other variable, then this condition is called **interaction**.

####Anova with Blocking in SAS

```
/*st102d04.sas*/
proc glm data=sasuser.MGGarlic_Block plots(only)=diagnostics;
     class Fertilizer Sector;
     model BulbWt=Fertilizer Sector;
     title 'ANOVA for Randomized Block Design';
run;
quit;
```

The blocking variable must be in the model and it must be listed in the class statement.

Output:
```
									Dependent Variable: BulbWt

                                              Sum of
      Source                      DF         Squares     Mean Square    F Value    Pr > F

      Model                       10      0.02307263      0.00230726       5.86    0.0003

      Error                       21      0.00826745      0.00039369

      Corrected Total             31      0.03134008


                      R-Square     Coeff Var      Root MSE    BulbWt Mean

                      0.736202      9.085064      0.019842       0.218398


      Source                      DF       Type I SS     Mean Square    F Value    Pr > F

      Fertilizer                   3      0.00508630      0.00169543       4.31    0.0162
      Sector                       7      0.01798632      0.00256947       6.53    0.0004


      Source                      DF     Type III SS     Mean Square    F Value    Pr > F

      Fertilizer                   3      0.00508630      0.00169543       4.31    0.0162
      Sector                       7      0.01798632      0.00256947       6.53    0.0004
```


The overall test p-value = 0.0003 indicates that there are significant differences between the means of the garlic bulb weights across fertilizers or blocks (sectors). However, because there is more than one term in the model, you *cannot* tell whether the differences are due to differences among the fertilizers or differences across sectors.

Because our P-value for fertilizer is 0.0162, there is a difference between fertilizers
Because the p-value in our sector is 0.0004, there is a difference between each of the blocks, and therefore blocking was required.

Because we chose 4 specific fertilizers, we can only make inferences on those 4 specific fertilizers (fixed-effects model)

**Diagnostics:**
	- Good random scatter of residuals
	- Decent looking Q-Q test

Now we want to know which pairs of fertilizers are garlic bulb weights different form one another?


###2.4 ANOVA Post Hoc Tests

Objectives
* Perform pairwise comparisons among groups after finding a significant effect of an independent variable in ANOVA
* Demonstrate graphical features in proc GLM for performing post hoc tests
* Interpret a diffogram
* Interpret a control plot

When we control the **comparisonwise error rate** (CER), we fix the level of alpha for a single comparison, without taking into consideration all the pairwise comparisons we are making.

The **experimentwise error rate** (EER) uses an alpha that takes into consideration all the pariwise comparisons that you are making. Chance that you falsely conclude that at least one difference exists is much higher when you consider all possible comparisons.

Control Comparisonwise Error Rate -> Pairwise t-tests

Control Experimentwise Error Rate -> Compair all pairs tukey, compare to control dunnett

All of the multiple comparison methods are requested with options in the `LSMEANS` statment of `proc glm`

**Comparison Control** :  `lsmeans / pdiff=all adjust=t`

**Experimentwise Control**  :  `lsmeans / pdiff=all adjust=tukey` or 
							`pdiff=control('control level') adjust=dunnett`

Tukey's multiple comparison method:
* Appropriate when you consider pairwise comparisons only
* The experimentwise error rate is
	* Equal to alpha when all pairwise comparisons are considered
	* Less than alpha when fewer than all pairwise comparisons are considered

**Use a diffogram to tell whether two group means are statistically significant**

![alt text](Pictures/Diffogram.PNG)


#### Special case of comparing to a control
Comparing to a control is appropriate when there is a natural reference group (ie placebo in a drug trial)

This is an example of the dunnet method

![alt text](Pictures/Control_Plot.png)

If confidence interval is in shaded region, then they are not statistically different.

####Post Hoc Pairwise Comparisons in SAS

```
/*st102d05.sas*/
proc glm data=sasuser.MGGarlic_Block 
         plots(only)=(controlplot diffplot(center));
    class Fertilizer Sector;
    model BulbWt=Fertilizer Sector;
    lsmeans Fertilizer / pdiff=all adjust=tukey;
    lsmeans Fertilizer / pdiff=control('4') adjust=dunnett;
    lsmeans Fertilizer / pdiff=all adjust=t;
    title 'Garlic Data: Multiple Comparisons';
run;
quit;

```
`plot=` **options**:

`controlplot` = requests display in which least squares means are compared against a reference level. LS mean control plots only produced when you specify `pdiff=control` or `adjust=dunnett` in lsmeans statement

`diffplot` = modifies diffogram produced by lsmeans statement with the `pdiff=all` option. `center` marks center point for each comparison.

`lsmeans` **options**:

`pdiff=` = requests p-values for differences, which is the probability of seeing a difference between two means that is as large as the observed means or larger if the two populations means are actually the same.

`adjust=` specifies the adjustment method for multiple comparisons.
* `T` asks that no adjustment made for multiple comparisons
* `Tukey` uses Tukey
* `Dunnet` uses dunnet

Results below show p-values the diffogram represents:

```
                                      Least Squares Means

                                                BulbWt      LSMEAN
                            Fertilizer          LSMEAN      Number

                            1               0.23625000           1
                            2               0.21115125           2
                            3               0.22330125           3
                            4               0.20288875           4


                          Least Squares Means for effect Fertilizer
                             Pr > |t| for H0: LSMean(i)=LSMean(j)

                                  Dependent Variable: BulbWt

                 i/j              1             2             3             4

                    1                      0.0195        0.2059        0.0029
                    2        0.0195                      0.2342        0.4143
                    3        0.2059        0.2342                      0.0523
                    4        0.0029        0.4143        0.0523


NOTE: To ensure overall protection level, only probabilities associated with pre-planned
      comparisons should be used.
```

By Tukey test, 1 and 4 are different.
By Dunnett, 1 and 4 are different
By T test, 1 and 4 are different and 2 and 1 are different (NOT TRUE DONT USE THIS TEST)


### 2.5 Two-Way ANOVA with Interactions

Objectives
* Fit a two-way ANOVA model
* Detect interactions between factors
* Analyze the treatments when there is a significant interaction

N-way ANOVA

![alt text](Pictures/Nway_Anova.png)

Drug example: The purpose of the study is to look at the effect of a new prescription drug on blood pressure

`DrugDose` dosage level of drug (1, 2, 3, 4) corresponding to (Placebo, 50mg, 100mg, 200mg)

`Disease` heart disease category

`BloodP` change in diastolic blood pressure after 2 weeks treatment

![alt text](Pictures/BloodP_Model.png)

An interaction occurs when the differences between group means on one variable change at different levels of another variable.

If an interaction exists between any factors, the tests for the individual factor effects might be misleading, deo to masking of the effects by the interaction. This is especially true for unbalanced data.

If the lines of an interaction graph are parallel, we can say that there is no interaction between variables.

Analyze the main effects with the interaction in the model:

$\Gamma_{ijk} = \mu + \alpha_i + \Beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk}$

or delete the interaction from the model and then analyze the main effects:

$\Gamma_{ijk} = \mu + \alpha_i + \Beta_j + \epsilon_{ijk}$

#### Two-Way ANOVA with Interactions in SAS

```
/*st102d06.sas*/  /*Part A*/
proc print data=sasuser.drug(obs=10);
    title 'Partial Listing of Drug Data Set';
run;

/*st102d06.sas*/  /*Part B*/
proc format;
    value dosefmt 1='Placebo'
                  2='50 mg'
                  3='100 mg'
                  4='200 mg';
run;

proc means data=sasuser.drug
           mean var std nway;
    class Disease DrugDose;
    var BloodP;
  format DrugDose dosefmt.;
    output out=means mean=BloodP_Mean;
    title 'Selected Descriptive Statistics for Drug Data Set';
run;
```

`nway` = when you include `class` variables, `nway` specifies that the output data set contains only statistics for the observations with the hightest type and way values.

Results:

```

                                  Analysis Variable : BloodP

                      Drug         N
           Disease    Dose       Obs            Mean        Variance         Std Dev
           ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
           A          Placebo     12       1.3333333     183.1515152      13.5333483

                      50 mg       16      -9.6875000     356.7625000      18.8881577

                      100 mg      13     -26.2307692     329.0256410      18.1390640

                      200 mg      18     -22.5555556     445.0849673      21.0970369

           B          Placebo     15      -8.1333333     285.9809524      16.9109714

                      50 mg       15       5.4000000     479.1142857      21.8886794

                      100 mg      14      24.7857143     563.7197802      23.7427838

                      200 mg      13      23.2307692     556.3589744      23.5872630

           C          Placebo     14       0.4285714     411.8021978      20.2929100

                      50 mg       13      -4.8461538     577.6410256      24.0341637

                      100 mg      14      -5.1428571     195.5164835      13.9827209

                      200 mg      13       1.3076923     828.5641026      28.7847894
           ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ

```



Let's plot it!

```
/*st102d06.sas*/  /*Part C*/
proc sgplot data=means;
    series x=DrugDose y=BloodP_Mean / group=Disease markers;
    xaxis integer;
    title 'Plot of Stratified Means in Drug Data Set';
  format DrugDose dosefmt.;
run;
```

`series` statement creates a line plot

`markers` adds data point markers to the series plot data points

`xaxis integer` forces the x-axis to have tick marks only at integer values


```
/*st102d06.sas*/  /*Part D*/
proc glm data=sasuser.drug order=internal;
    class DrugDose Disease;
    model Bloodp=DrugDose Disease DrugDose*Disease;
    title 'Analyze the Effects of DrugDose and Disease';
    title2 'Including Interaction';
  format DrugDose dosefmt.;
run;
quit;
```

results:

```

Dependent Variable: BloodP

                                              Sum of
      Source                      DF         Squares     Mean Square    F Value    Pr > F

      Model                       11      36476.8353       3316.0759       7.66    <.0001

      Error                      158      68366.4589        432.6991

      Corrected Total            169     104843.2941


                      R-Square     Coeff Var      Root MSE    BloodP Mean

                      0.347918     -906.7286      20.80142      -2.294118


      Source                      DF       Type I SS     Mean Square    F Value    Pr > F

      DrugDose                     3        54.03137        18.01046       0.04    0.9886
      Disease                      2     19276.48690      9638.24345      22.27    <.0001
      DrugDose*Disease             6     17146.31698      2857.71950       6.60    <.0001


      Source                      DF     Type III SS     Mean Square    F Value    Pr > F

      DrugDose                     3       335.73526       111.91175       0.26    0.8551
      Disease                      2     18742.62386      9371.31193      21.66    <.0001
      DrugDose*Disease             6     17146.31698      2857.71950       6.60    <.0001

```

Although the P-value for drug dose is high (almost 1), it does not mean that there is no effect in drug dose. If there is an interaction between drug dose and disease, we have to keep our main effect.

Looking on the graph, you can see that the drug dose relationship for disease A and disease B 'cancel each other out'



```
/*st102d06.sas*/  /*Part E*/
ods graphics off;
ods select LSMeans SlicedANOVA;
proc glm data=sasuser.drug order=internal;
    class DrugDose Disease;
    model Bloodp=DrugDose Disease DrugDose*Disease;
    lsmeans DrugDose*Disease / slice=Disease;
    title 'Analyze the Effects of DrugDose';
    title2 'at Each Level of Disease';
  format DrugDose dosefmt.;
run;
quit;

ods graphics on;

```

Results for lsmeans:

```
 DrugDose*Disease Effect Sliced by Disease for BloodP

                                       Sum of
            Disease        DF         Squares     Mean Square    F Value    Pr > F

            A               3     6320.126747     2106.708916       4.87    0.0029
            B               3           10561     3520.222833       8.14    <.0001
            C               3      468.099308      156.033103       0.36    0.7815

```

Taking disease x, puts it in its own data set, and run an anova against drug dose




# Day 5

## Chapter 5: Categorical Data Analysis

### 5.1 Describing Categorical Data

Objectives
* Examine the distribution of categorical variables
* Do preliminary examinations of associans between variables

Categorical variables association
* An associacion exists between two categorical variables if the distribution of one variable changes when the other variable changes
* For no assiciation, the distribtion of the first variable stays constant for different levels of the other variable

#### Crosstabulation Tables

Crosstabulation table shows the number of observations for each combination of the row and column variables.

By default, 4 measures in each cell
- Frequency
- Percent
- Row Percent
- Column Percent

#### Proc Freq

```
proc freq data=sas-data-set;
  tables table-requests / options;
run;
```

`tables` requests tables and specifies options for producing tests.
- General form is variable1*variable2*... where any number can be put in the tables statment.
  - For 2 way, first represents rows and second represents columns

#### Titanic example

- 2,223 passengers
- 1,517 fatalities

Variables:
- Survival statuss (1 or 0)
- Age
- Gender
- Class (1,2,3)
- Fare (cumulative total for a purchase for each person in a party)

Code:

```
/*st105d01.sas*/
title;
proc format;
    value survfmt 1 = "Survived"
                  0 = "Died"
                  ;
run;

proc freq data=sasuser.Titanic;
    tables Survived Gender Class
           Gender*Survived Class*Survived /
           plots(only)=freqplot(scale=percent);
    format Survived survfmt.;
run;

proc univariate data=sasuser.Titanic noprint;
    class Survived;
    var Age ;
    histogram Age;
    inset mean std median min max / format=5.2 position=ne;
    format Survived survfmt.;
run;
```

`FREQPLOT(<suboptions>)` requests a frequency plot. Available for frequency and crosstabulation tables

`(Scale=)` specifies the scale of the frequencies to display. Default is `Scale=freq`. Can also use `scale=percent`

In proc univariate, the line that reads:
`inset mean std median min max / format=5.2 position=ne;`
will put all of those variables in the same plot of the histogram.

We look at the distribution of survived, gender and class. Also look at the crosstabulation of gender*survived, and class*survived.

```

                                      The FREQ Procedure

                                                      Cumulative    Cumulative
                 Survived    Frequency     Percent     Frequency      Percent
                 ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                 Died             809       61.80           809        61.80
                 Survived         500       38.20          1309       100.00


                                                     Cumulative    Cumulative
                  Gender    Frequency     Percent     Frequency      Percent
                  ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                  female         466       35.60           466        35.60
                  male           843       64.40          1309       100.00


                                                    Cumulative    Cumulative
                  Class    Frequency     Percent     Frequency      Percent
                  ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                      1         323       24.68           323        24.68
                      2         277       21.16           600        45.84
                      3         709       54.16          1309       100.00


                                  Table of Gender by Survived

                              Gender     Survived

                              Frequency‚
                              Percent  ‚
                              Row Pct  ‚
                              Col Pct  ‚Died    ‚Survived‚  Total
                              ƒƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆ
                              female   ‚    127 ‚    339 ‚    466
                                       ‚   9.70 ‚  25.90 ‚  35.60
                                       ‚  27.25 ‚  72.75 ‚
                                       ‚  15.70 ‚  67.80 ‚
                              ƒƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆ
                              male     ‚    682 ‚    161 ‚    843
                                       ‚  52.10 ‚  12.30 ‚  64.40
                                       ‚  80.90 ‚  19.10 ‚
                                       ‚  84.30 ‚  32.20 ‚
                              ƒƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆ
                              Total         809      500     1309
                                          61.80    38.20   100.00


```

More women survived while more men died according to our crosstabulation table. It also turns out that as the higher class you are, the more chance you have of surviving (most of the lower class were men).

### 5.2 Tests of Association

Objectives
- Perform a chi-square test for association
- Examine the strength of association
- Calculate exact p-values
- Perform a Mantel-Haenszel chi-square test

Using contingency table analysis!

Assumng the same titanic example:

**Null Hypothesis** = There is no association between gender and surival. The probability of surviving the titanic class was the same whether you were male or female

**Alternative Hypothesis** = There **is** an association between gender and survival.


#### Chi-Square Test

**No Association** - Observed frequencies = Expected frequencies

**Association** - Observed frequencies ~= Expected frequencies

![alt text](Pictures/chi_squared_eq.png)

This equation tests whether an association exists. It **does not** measure the strength of an association. It depends on sample size.

The p-value for the chi-square test only indicates how confident you can be that the null hypothesis of no association is false. Doubling the size of the sample by duplicating each observation will double the value of the chi-square statistic, even though the strength of the association does not change.

**Cramer's V statistic** can measure the strength of the association.

- Has a range of -1 to 1 for 2 by 2 tables and 0 to 1 for larger tables. Values farther from 0 indicate stronger association

#### Odds Ratio

Odds ratio indicates how much more likely, **with respect to odds**, a certain event occurs in one group relative to its occurence in another group

![alt test](Pictures/odds_eq.png)

**Odds** are calculated **from** probabilities.

**Odds ratio** is the ratio of odds, as seen below:

![alt test](Pictures/odds_ratio_ex.png)

Group A had 1/3 the odds of group B **OR** Group B had 3 time the odds of having the outcome compared to group A.

#### Chi-Square Test in SAS

```
/*st105d02.sas*/
ods graphics off;
proc freq data=sasuser.Titanic;
    tables (Gender Class)*Survived
          / chisq expected cellchi2 nocol nopercent 
            relrisk;
    format Survived survfmt.;
    title1 'Associations with Survival';
run;

ods graphics on;
```

`Chisq` produces chi-square test of association and the measures of association based on chi-square statistic

`Expected` prints the expected cell frequencies under the hypothesis of no association

`CellChi2` prints each cell's contribution to th total chi-square statistic

`Nocol` suppresses column percentages

`Nopercent`suppresses cell percentages

`Relrisk` prints a table with risk ratios (probability ratios) and odds ratios

Results:

```
                       The FREQ Procedure

                                  Table of Gender by Survived

                           Gender          Survived

                           Frequency      ‚
                           Expected       ‚
                           Cell Chi-Square‚
                           Row Pct        ‚Died    ‚Survived‚  Total
                           ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆ
                           female         ‚    127 ‚    339 ‚    466
                                          ‚    288 ‚    178 ‚
                                          ‚ 90.005 ‚ 145.63 ‚
                                          ‚  27.25 ‚  72.75 ‚
                           ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆ
                           male           ‚    682 ‚    161 ‚    843
                                          ‚    521 ‚    322 ‚
                                          ‚ 49.753 ‚ 80.501 ‚
                                          ‚  80.90 ‚  19.10 ‚
                           ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆƒƒƒƒƒƒƒƒˆ
                           Total               809      500     1309


                          Statistics for Table of Gender by Survived

                    Statistic                     DF       Value      Prob
                    ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                    Chi-Square                     1    365.8869    <.0001
                    Likelihood Ratio Chi-Square    1    372.9213    <.0001
                    Continuity Adj. Chi-Square     1    363.6179    <.0001
                    Mantel-Haenszel Chi-Square     1    365.6074    <.0001
                    Phi Coefficient                      -0.5287
                    Contingency Coefficient               0.4674
                    Cramer's V                           -0.5287


                                     Fisher's Exact Test
                              ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                              Cell (1,1) Frequency (F)       127
                              Left-sided Pr <= F       7.351E-83
                              Right-sided Pr >= F         1.0000

                              Table Probability (P)    6.705E-83
                              Two-sided Pr <= P        7.918E-83
```

The cell for survived=1 and Gender=female has the highest Chi-Square value (145.63). It contributes the most to the chi-square statistic.

p-value for chi-square statistic is <.0001 < 0.05. We reject null hypothesis. **There is evidence of an association between gender and survived**.

Strength of this association is realatively strong since Cramer's V is -0.5287

```
 The FREQ Procedure

                          Statistics for Table of Gender by Survived

                          Estimates of the Relative Risk (Row1/Row2)

               Type of Study                   Value       95% Confidence Limits
               ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
               Case-Control (Odds Ratio)      0.0884        0.0677        0.1155
               Cohort (Col1 Risk)             0.3369        0.2894        0.3921
               Cohort (Col2 Risk)             3.8090        3.2797        4.4239

                                      Sample Size = 1309

```

**Relative Risk** table shows another measure of strength association.
- Odds ratio shown in first row of table with 95% confidence limits. Interpreted as the odds of a top row value to be in the left column compared with the same odds in the bottom row.
- In this case, a female has 0.0884 (9%) of the odds of dying compared with a male.

**Cohort estimates** for each column interpreted as **probability ratios, not odds ratios**. You get the choice of assessing probabilities of left column (col1) or right column (col2).
  - The col1 risk shows the ratio of probabilities of females to males being in the left column (27.25/80.90)=0.3369

##### When not to use Chi-Squared

Do not use assymptotic chi-squared test when more than 20% of cells have expected counts less than 5!

p-values are based on the assumption that the test statistic follows a particular distribution when the sample size is sufficiently large.

For small sample size, we calculate **Exact** p-values

For large sample size, we calculate **Asymptotic** p-values. It takes a lot of time and memory to compute exact p-values since SAS calculates *every* possible combination of crosstabulation frequencies.

Exact p-values for Pearson Chi-Square

![alt text](Pictures/exact_pvalues_pearsonchi.png)

The exact p-value is the sum of probabilities of all tables with X^2 values **as great or greater** than that of the observed table!

#### Exact p-values for Pearson Chi-Square in SAS

```
/*st105d03.sas*/
ods graphics off;
proc freq data=sasuser.exact;
   tables A*B / chisq expected cellchi2 nocol nopercent;
   title "Exact P-Values";
run;

ods graphics on;

```

Results:

```
                               Statistics for Table of A by B

                    Statistic                     DF       Value      Prob
                    ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                    Chi-Square                     1      2.1000    0.1473
                    Likelihood Ratio Chi-Square    1      2.8306    0.0925
                    Continuity Adj. Chi-Square     1      0.3646    0.5460
                    Mantel-Haenszel Chi-Square     1      1.8000    0.1797
                    Phi Coefficient                      -0.5477
                    Contingency Coefficient               0.4804
                    Cramer's V                           -0.5477

                     WARNING: 100% of the cells have expected counts less
                              than 5. Chi-Square may not be a valid test.


                                     Fisher's Exact Test
                              ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                              Cell (1,1) Frequency (F)         0
                              Left-sided Pr <= F          0.2857
                              Right-sided Pr >= F         1.0000

                              Table Probability (P)       0.2857
                              Two-sided Pr <= P           0.4286

                                        Sample Size = 7

```

Warning suggests that p-value should not be trusted.

Want to report the two-sided Pr <= P value.

Difference between exact p-value (0.4286) and asymptotic p-value (0.1473). Exact tests tend to be more conservative than asymptotic tests


#### Ordinal Variables - Mantel-Haenszel Chi-square test

**Null Hypothesis** : There is no ordinal association between the row and column variables

**Alternative Hypothesis** : There is an ordinal association between the row and column variables

The Mantel-Haenszel Chi-Square Test determines whether an ordinal association exists. **Does Not** measure the strength of the ordinal association
- More powerful than the general association chi-squared statistic for detecting an ordinal association
  - All of the Mantel-Haenszel statistic's power is concentrated toward that objective
  - Power of the general association statistic is dispersed over a greater number of alternatives

#### Spearman Correlation Statistic

To measure strength of ordinal association, you can use Spearman
- Has range between -1 and 1
- Has values close to 1 if there is relatively high degree of positive correlation
- Has values close to -1 if there is a relatively high degree of negative correlation
- Appropriate only if both variables are ordinal scaled and the values are in logical order

**Spearman** correlation uses ranks of the data

**Pearson** correlation uses the observed values when variable is numeric

#### Using SAS

```
/*st105d04.sas*/
ods graphics off;
proc freq data=sasuser.Titanic;
    tables Class*Survived / chisq measures cl;
    format Survived survfmt.;
    title1 'Ordinal Association between CLASS and SURVIVAL?';
run;

ods graphics on;
```

`chisq` produces Pearson chi-square, likelihood-ratio chi-square, and the Mantel-Haenszel chi-square. Also produces measures of association based on chi-square such as the phi coefficient, contingency coefficient and Cramer's V

`measures` produces Spearman correlation statistic and other measures of association

`CL` produces confidence bounds for the `measures` statistics

Results of mantel-Haenszel:

```
                         Statistics for Table of Class by Survived

                    Statistic                     DF       Value      Prob
                    ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
                    Chi-Square                     2    127.8592    <.0001
                    Likelihood Ratio Chi-Square    2    127.7655    <.0001
                    Mantel-Haenszel Chi-Square     1    127.7093    <.0001
                    Phi Coefficient                       0.3125
                    Contingency Coefficient               0.2983
                    Cramer's V                            0.3125

```

Results of spearman:

```

                           Statistics for Table of Class by Survived

                                                                          95%
         Statistic                              Value       ASE     Confidence Limits
         ƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒƒ
         Gamma                                -0.5067    0.0375    -0.5801    -0.4332
         Kendall's Tau-b                      -0.2948    0.0253    -0.3444    -0.2451
         Stuart's Tau-c                       -0.3141    0.0274    -0.3677    -0.2604

         Somers' D C|R                        -0.2613    0.0226    -0.3056    -0.2170
         Somers' D R|C                        -0.3326    0.0286    -0.3887    -0.2765

         Pearson Correlation                  -0.3125    0.0267    -0.3647    -0.2602
         Spearman Correlation                 -0.3097    0.0266    -0.3619    -0.2576

         Lambda Asymmetric C|R                 0.1540    0.0331     0.0892     0.2188
         Lambda Asymmetric R|C                 0.0317    0.0320     0.0000     0.0944
         Lambda Symmetric                      0.0873    0.0292     0.0301     0.1445

         Uncertainty Coefficient C|R           0.0734    0.0127     0.0485     0.0983
         Uncertainty Coefficient R|C           0.0485    0.0084     0.0320     0.0650
         Uncertainty Coefficient Symmetric     0.0584    0.0101     0.0386     0.0782

                                      Sample Size = 1309

```

Spearman correlation (-0.3097) indicates that there is amoderate, negative ordinal relationship between class and survival

ASE is asymptotic standard error (0.0266). Measure of standard error for larger samples (larger than 25 foe each degree of freedom in the Pearson chi-square stat)

95% confidence interval (-0.3619, -0.2576) for spearman correlation statistic does not conatain 0, and tehrefore the relationship is significant at the 0.05 significance level.


### Introduction to Logistic Regression

Objectives
- Define the concepts of logistic regression
- Fit a binary logistic regression model using the `logistic` procedure
- Describe the standard output form the logistic procedure with one continuous predictor variable
- read and interpret odds ratio talbes and plots

![alt text](Pictures/cont_vs_cat.png)

If response variable is dichotomous (two categories), appropriate logistic regression model is binary logistic regression

If more than 2 categories within response variable, then there are 2 possibilities
- If response is nominal -> fit a *nominal* logistic regression model
- If response is ordinal -> fit a *ordinal* logistic regression model

![alt text](Pictures/ols_reg.png)     vs    ![alt text](Pictures/lpm_model.png)

But can we really use a linear mondel?

Also, there is no such thing as an observed probability -> least squares methods cannot be used since there are no residuals.

Logistic regression model:

![alt text](Pictures/log_reg_model.png)

Logit Transformation:

![alt text](Pictures/logit_t.png)

`i` = indexes all cases (observations)

`p_i` = probability that the even (ex. a sale) occurs in the ith case

`ln` = natural log 

- Modeling probability has bounds of 0 and 1
- The logit has no upper or lower bounds
- Logit is the natural log of the odds

##### Assumption in logistic regression

Logit has a linear relationship with the predictor variables.

We are assuming that the relationship between our variable and probability follows the 'S' curve. This is so that we get a linear relationship between the logit and our variable.

Our logistic regression model therefore becomes:

![alt text](Pictures/real_log_reg_model.PNG)

#### Proc logistic

Code:

```
proc logistic data=sas-data-set options
  class variables / options;
  model response=predictors / options;
  units independent1=list ... / options;
  oddsratio 'label' variable / options;
  output out=sas-data-set keyword=name / options;
run;
```

`class` names the classification variables to be used in the analysis. Must precede `model` statement. By default, will be analyzed using effects coding

`model` specifies response and predictor variables

`output` creates output data set from input data and any requested statistics

`units` enables you to obtain odds ratio estimate for specified change in a predictor variable

`oddsratio` produces odds ratios for variables even when variables are involved in interactions with other covariates, and for classification variables that use any parameterization.

 ```
/*st105d05.sas*/
proc logistic data=sasuser.Titanic
              plots(only)=(effect oddsratio);
    model Survived(event='1')=Age / clodds=pl;
    title1 'LOGISTIC MODEL (1):Survived=Age';
run;
```

`effect` requests a plot of predicted prob on y axis by predictor on the x axis

`oddsratio` requests a plot of the odds ratio (along with its (1-alpha) confidence limits). Width can be changed using `alpha=` option in `proc logistic` statement

`(event=)` specifies the event category for the binary response model. `proc logistic` models the probability of each event. Can specify value of event category in quotes or specify one of the following keywords:
- `first` designates the first ordered category as the evnet
- `last` designates the last ordered category as the event

`clodds=pl` requests **profile likelihood** confidence intervals for the odds ratio of all predictor variables, which are desirable for small sample sizes.

```
 Response Profile

                               Ordered                      Total
                                 Value     Survived     Frequency

                                     1            0           619
                                     2            1           427

                              Probability modeled is Survived=1.

NOTE: 263 observations were deleted due to missing values for the response or explanatory
      variables.


                                   Model Convergence Status

                        Convergence criterion (GCONV=1E-8) satisfied.


                                     Model Fit Statistics

                                                         Intercept
                                          Intercept            and
                            Criterion          Only     Covariates

                            AIC            1416.620       1415.301
                            SC             1421.573       1425.207
                            -2 Log L       1414.620       1411.301

```

The smaller the SC the better. Smaller the AIC the better.

```

                                    The LOGISTIC Procedure

                            Testing Global Null Hypothesis: BETA=0

                    Test                 Chi-Square       DF     Pr > ChiSq

                    Likelihood Ratio         3.3191        1         0.0685
                    Score                    3.3041        1         0.0691
                    Wald                     3.2932        1         0.0696


                           Analysis of Maximum Likelihood Estimates

                                             Standard          Wald
              Parameter    DF    Estimate       Error    Chi-Square    Pr > ChiSq

              Intercept     1     -0.1335      0.1448        0.8501        0.3565
              Age           1    -0.00800     0.00441        3.2932        0.0696


                 Association of Predicted Probabilities and Observed Responses

                      Percent Concordant      51.3    Somers' D    0.050
                      Percent Discordant      46.4    Gamma        0.051
                      Percent Tied             2.3    Tau-a        0.024
                      Pairs                 264313    c            0.525


               Odds Ratio Estimates and Profile-Likelihood Confidence Intervals

                  Effect         Unit     Estimate     95% Confidence Limits

                  Age          1.0000        0.992        0.983        1.001

```

For global F-test, we can use either Likelihood Ratio, Score or Walk. **Use Likelihood Ratio**.

Our model is not very good to begin with (Likelihood p-value > 0.05)

For specific beta value, we use Analysis of Maximum Likelihood Estimates table. Age is not statistically significant (P-value = 0.0696 >0.05)

For odds ratio estimate, as age increases by 1, you have 0.992 times the odds of surviving (estimate).

Aka: As age increase by one, the odds of surviving decrease by 0.008%
- odds after / odds before = 0.250

![alt text](Pictures/lrm_odds_ratio.png)

You can also look at the confidence interval in the odds to see whether age is a statistically significant variable.

![alt text](Pictures/lrm_odds_ratio_ci.png)

Because we are 95% confident that the true odds ratio is between 0.983 and 1.001, and this interval includes 1.000, the odds ratio is not significant at the 0.05 level



##### Model assessment: Comparing pairs

Counting concordant, discordant, and tied pairs is a way to assess how well the model predicts its own data and thus, how well the model fits

In general, want high percentage of concordant pairs, and low percentages of discordant and tied pairs

We must compare everyone who had the outcome of interest against everyone who did not

Concordant pair
- Dead at age 30 P(survived) = 0.4077
- Survived at age 20 P(survived) = 0.4274

Discordant pair
- Dead at age 35 P(S) = 0.3981
- Survived at age 45 P(S) = 0.3791

Tied pair
- 2 50 year olds, one dead one alive P(S) = 0.3697

Association of Predicted Probabilities and Observed Responses table lists the several measures of association to help assess predictive ability of logistic model.


### 5.4 Logistic Regression with Categorical Predictors

Objectives
- State how a logistic model with categorical predictors does and does not differe from one with continuous predictors
- Describe what a `class` statement does
- Define the standard output from the `logistic` procedure with categorical predictor variables

![alt text](Pictures/cat_vs_cat_log.png)

#### Class statement

Creates a set of 'design variables' representing the information in the categorical variables
- Character variables cannot be used, as is, in a model
- Design variables are ones actually used in model calculations
- Exist several 'parameterizations' available in `proc logistic`

**Note:** By default, SAS uses effects coding

![alt text](Pictures/effects_coding.png)

Number of design variables created is number of levels of the `class` variable minus 1

Effects coding measures the difference between a design variable and the overall average.

##### Effects Coding example

![alt text](Pictures/logit_effect_coding.png)

If B_x is close to zero, then there is no difference (probabilistically) between D_x and the average

##### Reference (Dummy) Coding

![alt text](Pictures/dummy_coding.png)

Reference coding measures the difference between a design variable and a reference variable.

Each non reference B_x represents the difference of the logits for level x and the reference level

The reference B_x represents the value of the logit when at the reference level

Reference coding and effects coding does not necessarily agree in p-values because they test for different things.

#### Multiple Logistic Regression

```
/*st105d06.sas*/
proc logistic data=sasuser.Titanic plots(only)=(effect oddsratio);
    class Gender(ref='male') Class(ref='3') / param=ref;
    model Survived(event='1')=Age Gender Class / clodds=pl;
    units age=10;
    title1 'LOGISTIC MODEL (2):Survived=Age Gender Class';
run;
```

`units` enables you to specify units of change for continuous explanatory variables so that customized odds ratios can be estimated

`(ref='level') specifies the event category chosen as the reference level when using reference or effect parameterization. Default is `ref=last`

`param=` specifies parametrization. Can specify for each variable name by typing it within parentheses after variable name.

Results:

```
                                   Class Level Information

                                                        Design
                                Class      Value      Variables

                                Gender     female      1
                                           male        0

                                Class      1           1      0
                                           2           0      1
                                           3           0      0


                                   Model Convergence Status

                        Convergence criterion (GCONV=1E-8) satisfied.


```

SAS will show coding itself if you do class statement

```
                                    The LOGISTIC Procedure

                                     Model Fit Statistics

                                                         Intercept
                                          Intercept            and
                            Criterion          Only     Covariates

                            AIC            1416.620        992.315
                            SC             1421.573       1017.079
                            -2 Log L       1414.620        982.315


                            Testing Global Null Hypothesis: BETA=0

                    Test                 Chi-Square       DF     Pr > ChiSq

                    Likelihood Ratio       432.3052        4         <.0001
                    Score                  386.1522        4         <.0001
                    Wald                   277.3202        4         <.0001


                                  Type 3 Analysis of Effects

                                                  Wald
                          Effect      DF    Chi-Square    Pr > ChiSq

                          Age          1       29.6314        <.0001
                          Gender       1      226.2235        <.0001
                          Class        2      103.3575        <.0001


                           Analysis of Maximum Likelihood Estimates

                                                Standard          Wald
          Parameter           DF    Estimate       Error    Chi-Square    Pr > ChiSq

          Intercept            1     -1.2628      0.2030       38.7108        <.0001
          Age                  1     -0.0345     0.00633       29.6314        <.0001
          Gender    female     1      2.4976      0.1661      226.2235        <.0001
          Class     1          1      2.2907      0.2258      102.8824        <.0001
          Class     2          1      1.0093      0.1984       25.8849        <.0001


```

AIC, SC and -2 Log L have all dropped, which is good.

Likelihood ratio is good, and therefore one of are variables is statistically significant.

Type 3 Analysis of effects show that age, gender and class are all statistically significant to predict survival. Significance in this table means that some difference in level of a variable is significant.

Analysis of Maximum likelihood estimates shows that both class 1 and class 2 are statistically different than class 3 to model who survived.

```
                            The LOGISTIC Procedure

                 Association of Predicted Probabilities and Observed Responses

                      Percent Concordant      83.8    Somers' D    0.680
                      Percent Discordant      15.8    Gamma        0.683
                      Percent Tied             0.4    Tau-a        0.329
                      Pairs                 264313    c            0.840


               Odds Ratio Estimates and Profile-Likelihood Confidence Intervals

           Effect                        Unit     Estimate     95% Confidence Limits

           Age                        10.0000        0.708        0.625        0.801
           Gender female vs male       1.0000       12.153        8.823       16.925
           Class  1 vs 3               1.0000        9.882        6.395       15.513
           Class  2 vs 3               1.0000        2.744        1.863        4.059

```

We want high values of concordant, and high values of discordant. This model is much better than the old model.

9.882x the odds of survival if you were a class 1 traveller compared to class 3

No odds ratios confidence intervals contain 1, therefore all variables are all significant.


### 5.5 Stepwise Selection with Interaction

Objectives
- Fit a multiple logistic regression model with main effects and interactions using the backward elimination method
- Explain interactions using graphs

![alt text](Pictures/contcat_vs_cat.png)

Similar to proc reg, you can find a best subset model with `proc logistic` stepwise methods. **Default selection criteria changes to 0.05 for forward, backward, stepwise for slentry and slstay**.

#### Model Hierarchy

Model hierarchy refers to the requirement that, for any term to be in the model, all effects contained in the term must be present in the model.

For a more customized analysis, the `Hierarchy=` option specifies whether the hierarchy is maintained and whether a single effect or multiple effects are allowed to enter or leave the model in one step for forward, backward, and stepwise selection.

##### SAS code

```
/*st105d07.sas*/  /*Part A*/
proc logistic data=sasuser.Titanic plots(only)=(effect oddsratio);
    class Gender(ref='male') Class(ref='3') / param=ref;
    model Survived(event='1')=Age|Gender|Class @2 / 
          selection=backward clodds=pl slstay=0.01;
    units age=10;
    title1 'LOGISTIC MODEL (3): Backward Elimination '
           'Survived=Age|Gender|Class';
run;
```

The bar notation with the @2 constructs a model with all the main effects and the two-factor interactions. @3 constructs a model with all of the main effects, two way and three-factor interactions. 

`selection=` specifies method to select variables in model. Can be: `Backward`, `forward`, `selction`, `none`. `score represents best subset selection (default is `none`)

```

                                    The LOGISTIC Procedure

                                   Residual Chi-Square Test

                              Chi-Square       DF     Pr > ChiSq

                                 13.2931        3         0.0040


NOTE: No (additional) effects met the 0.01 significance level for removal from the model.


                                Summary of Backward Elimination

                      Effect                       Number          Wald
              Step    Removed              DF          In    Chi-Square    Pr > ChiSq

                 1    Age*Gender            1           5        4.3264        0.0375
                 2    Age*Class             2           4        8.8477        0.0120


                                  Type 3 Analysis of Effects

                                                     Wald
                       Effect            DF    Chi-Square    Pr > ChiSq

                       Age                1       32.5663        <.0001
                       Gender             1       40.0553        <.0001
                       Class              2       44.4898        <.0001
                       Gender*Class       2       43.9289        <.0001


                           Analysis of Maximum Likelihood Estimates

                                                   Standard          Wald
        Parameter                DF    Estimate       Error    Chi-Square    Pr > ChiSq

        Intercept                 1     -0.6552      0.2113        9.6165        0.0019
        Age                       1     -0.0385     0.00674       32.5663        <.0001
        Gender       female       1      1.3970      0.2207       40.0553        <.0001
        Class        1            1      1.5770      0.2525       38.9980        <.0001
        Class        2            1     -0.0242      0.2720        0.0079        0.9292
        Gender*Class female 1     1      2.4894      0.5403       21.2279        <.0001
        Gender*Class female 2     1      2.5599      0.4562       31.4930        <.0001

```

Selection is done for the best model, then gives you the results of that model.

Age and gender are useful.

Class 1 is different than class 3. Class 2 is not statistically different than class 3.

However, looking at gender and class, we see that females of class 2 are different than females of class 3.

Class bothers the relationship between gender and survival.

```
/*st105d07.sas*/  /*Part B*/
proc logistic data=sasuser.Titanic 
              plots(only)=oddsratio(range=clip);
    class Gender(ref='male') Class(ref='3') / param=ref;
    model Survived(event='1')=Age Gender|Class;
    units age=10;
    oddsratio Gender / at (Class=ALL) cl=pl;
    oddsratio Class / at (Gender=ALL) cl=pl;
    oddsratio Age / cl=pl;
    title1 'LOGISTIC MODEL (3.1): Survived=Age Gender|Class';
run;
```

`range=` with suboptions (min, max)|CLIP, specifies the range of the range of the displayed odds ratio axis. `Range=clip` has same effect as specifying the minimum odds ratio as min and the max odds ratio as max.

`oddsratio` produces odds ratios for a variable even when the variable is involved in interactions with other covariates, and for classification variables that use any parameterization. 

`AT` specifies fixed levels of the interacting covariates. 


# Summary of everything

In morning, take the concept assessment.
- No hand calculation
- No computer calculation
- No calculations
- Formula sheet provided
- Bring writing utensil (calculator if you want)
- True/false, multiple choice, short answer
  - LSR line
  - What is variance
  - All concept questions
- 3 hours to take it

In afternoon, SAS exam
- Open everything
- 3 problems already covered
  - Exercises/code done in class
  - Walking through all the problems
    - Explore data set
    - Give me blah blah blah
  - Need to provide output
  - Need to interpret output
  - Need to hand in code